{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNkKqNfwGT1V",
        "outputId": "ef50b188-e9ad-42df-f1a8-1cacafcaf3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/csc413/project\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pytorch-fid) (1.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from pytorch-fid) (8.4.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-fid) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-fid) (1.22.4)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-fid) (0.15.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1->pytorch-fid) (3.11.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.1->pytorch-fid) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.1->pytorch-fid) (16.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.2.2->pytorch-fid) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p /csc413/project/\n",
        "%cd /csc413/project\n",
        "%pip install pytorch-fid\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import shutil\n",
        "import torch\n",
        "import pickle\n",
        "import zipfile\n",
        "import torchvision\n",
        "import pytorch_fid\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from typing import Any\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOBw2JfGKeu_"
      },
      "outputs": [],
      "source": [
        "def download(zip_to_download_name, filename):\n",
        "  origin = \"https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/\"\n",
        "  origin += zip_to_download_name\n",
        "\n",
        "  datadir = os.path.join(\"data\")\n",
        "  if not os.path.exists(datadir):\n",
        "      os.makedirs(datadir)\n",
        "\n",
        "  zip_path = os.path.join(datadir, filename)\n",
        "  zip_path = zip_path + \".zip\"\n",
        "\n",
        "  urlretrieve(origin, zip_path)\n",
        "\n",
        "  with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "      zip_ref.extractall(datadir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "halpx1yVBDA4"
      },
      "outputs": [],
      "source": [
        "download(\"vangogh2photo.zip\", \"vangogh\")\n",
        "download(\"ukiyoe2photo.zip\", \"ukiyoe\")\n",
        "download(\"monet2photo.zip\", \"monet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJeMV7dW7AM8"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"/CSC413_test_data.zip\"):\n",
        "  %mv /CSC413_test_data.zip /csc413/project/CSC413_test_data.zip\n",
        "elif os.path.exists(\"/content/CSC413_test_data.zip\"):\n",
        "  %mv /content/CSC413_test_data.zip /csc413/project/CSC413_test_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "9IuysbsNu13I",
        "outputId": "185869af-1604-4b21-d290-4467f488ea74"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-72433173e8ae>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/csc413/project/CSC413_test_data.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdatadir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/csc413/project/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/csc413/project/CSC413_test_data.zip'"
          ]
        }
      ],
      "source": [
        "zip_path = \"/csc413/project/CSC413_test_data.zip\"\n",
        "datadir = \"/csc413/project/\"\n",
        "with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "      zip_ref.extractall(datadir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaFRTM4CLCbA"
      },
      "source": [
        "# Setup\n",
        "\n",
        "run the following code to load global variables and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgHgNU3XLe51"
      },
      "outputs": [],
      "source": [
        "# Define the size of the generated image\n",
        "img_size = 256\n",
        "\n",
        "# Define the weights to use for style mixing\n",
        "alpha = 0.5\n",
        "beta = 1 - alpha\n",
        "\n",
        "# Model URLs\n",
        "NST_Pretrained = \"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqAjqeQULig3"
      },
      "source": [
        "# Data Loading\n",
        "\n",
        "The following code load data for Model usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzueWe7OLiDL"
      },
      "outputs": [],
      "source": [
        "# Define a function to load and preprocess images\n",
        "def load_image(img_path: str) -> Any:\n",
        "    \"\"\"\n",
        "    Load and preprocess the image.\n",
        "\n",
        "    :param img_path: the path of image to load\n",
        "    :return: the processed image\n",
        "    \"\"\"\n",
        "    img = plt.imread(img_path)\n",
        "    img = np.array(img).astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eQYaw3WsLgzp"
      },
      "source": [
        "# NST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZKXnBp8LBxa"
      },
      "outputs": [],
      "source": [
        "class NST:\n",
        "    \"\"\"\n",
        "    The styleGAN pretrained-model.\n",
        "\n",
        "    Instance Variables:\n",
        "        - url: the url of the model\n",
        "        - model: the model of the pretrained model\n",
        "        - mixed_features: the mixed feature after mixing style 1 and 2\n",
        "    \"\"\"\n",
        "    _url: str\n",
        "    _model: Any\n",
        "    _mixed_features: Any\n",
        "\n",
        "    def __init__(self, url: str) -> None:\n",
        "        \"\"\"\n",
        "        Initialization\n",
        "\n",
        "        :param url: the url of the pretrained_model\n",
        "        \"\"\"\n",
        "        self._url = url\n",
        "\n",
        "    def _load_model(self) -> None:\n",
        "        \"\"\"\n",
        "        load the model\n",
        "        \"\"\"\n",
        "        self._model = hub.load(self._url)\n",
        "\n",
        "\n",
        "    def _mix(self, style1, style2) -> None:\n",
        "        \"\"\"\n",
        "        Mix the style of style1 and style2 corresponding to hyperparameter alpha and beta\n",
        "        and store the style into self.mixed_features\n",
        "\n",
        "        :param style1: source of style1\n",
        "        :param style2: source of style2\n",
        "        \"\"\"\n",
        "        self._mixed_features = self._model(tf.constant(style1), tf.constant(style2))[0]\n",
        "        self._mixed_features = self._mixed_features.numpy()\n",
        "\n",
        "    def _generate_and_save(self, output_path) -> None:\n",
        "        \"\"\"\n",
        "        Use self.model and self.mixed_features to generate the mixed pictures and store them\n",
        "        \"\"\"\n",
        "        img = self._mixed_features[0]\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        cv2.imwrite((output_path), img)\n",
        "\n",
        "    def generate(self, input, style, output_path) -> None:\n",
        "        \"\"\"\n",
        "        Now perform image generation using the model!\n",
        "\n",
        "        :param input: source of input\n",
        "        :param style: source of style\n",
        "        \"\"\"\n",
        "        self._load_model()\n",
        "        self._mix(input, style)\n",
        "        self._generate_and_save(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmVEXV1BleGk"
      },
      "outputs": [],
      "source": [
        "def rename_test_source(source):\n",
        "  source_dir = f\"test data/test_{source}\"\n",
        "\n",
        "  source_lst = os.listdir(source_dir)\n",
        "  print(source_lst)\n",
        "\n",
        "  for i in range(len(source_lst)):\n",
        "        source_path = os.path.join(source_dir, source_lst[i])\n",
        "        print(f\"{source} {i + 1} {source_path}\")\n",
        "        os.rename(source_path, os.path.join(source_dir, f\"source_{source}_{i + 1}.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d42F5UeR9h45"
      },
      "outputs": [],
      "source": [
        "def run_model(model, input, style, save_source=False): \n",
        "  # create folder to save output\n",
        "  output_dir = f\"out_image/{input}_to_{style}\"\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "  # get path for input and style\n",
        "  if input == \"photo\":\n",
        "    test_input_dir = f\"test data/test_{input}\"\n",
        "  else:\n",
        "    test_input_dir = f\"out_image/photo_to_{input}\"\n",
        "    if not os.path.exists(test_input_dir):\n",
        "      print(f\"cannot find result from first style transfer (photo -> {input})\")\n",
        "      return\n",
        "  test_style_dir = f\"test data/test_{style}\"\n",
        "  \n",
        "  test_input_lst = sorted(os.listdir(test_input_dir))\n",
        "  test_style_lst = sorted(os.listdir(test_style_dir))\n",
        "  \n",
        "  # perform style transfer for each pair of photo and style\n",
        "  for i in range(len(test_input_lst)):\n",
        "    input_path = os.path.join(test_input_dir, test_input_lst[i])\n",
        "    print(f\"{i + 1} input_path: {input_path}\")\n",
        "    style_path = os.path.join(test_style_dir, test_style_lst[i])\n",
        "    print(f\"{i + 1} style_path: {style_path}\")\n",
        "\n",
        "    input_img = load_image(input_path)\n",
        "    style_img = load_image(style_path)\n",
        "\n",
        "    output_path = os.path.join(output_dir, f\"out_{input}_to_{style}_{i + 1}.jpg\")\n",
        "\n",
        "    model.generate(input_img, style_img, output_path)\n",
        "\n",
        "    if (save_source): \n",
        "      shutil.copy(input_path, output_dir)\n",
        "      shutil.copy(style_path, output_dir)\n",
        "      os.rename(os.path.join(output_dir, test_input_lst[i]), os.path.join(output_dir, f\"source_{input}_{i + 1}.jpg\"))\n",
        "      os.rename(os.path.join(output_dir, test_style_lst[i]), os.path.join(output_dir, f\"source_{style}_{i + 1}.jpg\"))\n",
        "\n",
        "    print(f\"done {input} to {style} {i + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTWsxh-hynzA"
      },
      "outputs": [],
      "source": [
        "model = NST(NST_Pretrained)\n",
        "\n",
        "rename_test_source(\"photo\")\n",
        "rename_test_source(\"monet\")\n",
        "rename_test_source(\"vangogh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVyq3ovNxzzN"
      },
      "outputs": [],
      "source": [
        "run_model(model, \"photo\", \"monet\")\n",
        "run_model(model, \"photo\", \"vangogh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_wWBQWpDRww"
      },
      "outputs": [],
      "source": [
        "run_model(model, \"monet\", \"vangogh\")\n",
        "run_model(model, \"vangogh\", \"monet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fdIsuASPBPf"
      },
      "outputs": [],
      "source": [
        "def show_plot(figure, image, title, data_idx, plot_idx):\n",
        "  figure.add_subplot(nrows, ncols, plot_idx)\n",
        "  plt.title(f\"{title}_{data_idx}\")\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlJBZVC5HMnb"
      },
      "outputs": [],
      "source": [
        "i = 3\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "M = Image.open(f\"test data/test_monet/source_monet_{i}.jpg\")\n",
        "P = Image.open(f\"test data/test_photo/source_photo_{i}.jpg\")\n",
        "V = Image.open(f\"test data/test_vangogh/source_vangogh_{i}.jpg\")\n",
        "PtM = Image.open(f\"out_image/photo_to_monet/out_photo_to_monet_{i}.jpg\")\n",
        "PtV = Image.open(f\"out_image/photo_to_vangogh/out_photo_to_vangogh_{i}.jpg\")\n",
        "MtV = Image.open(f\"out_image/monet_to_vangogh/out_monet_to_vangogh_{i}.jpg\")\n",
        "VtM = Image.open(f\"out_image/vangogh_to_monet/out_vangogh_to_monet_{i}.jpg\")\n",
        "\n",
        "\n",
        "show_plot(fig, M, \"source_monet\", i, 1)\n",
        "show_plot(fig, P, \"source_photo\", i, 2)\n",
        "show_plot(fig, V, \"source_vangogh\", i, 3)\n",
        "\n",
        "show_plot(fig, PtM, \"photo_monet\", i, 4)\n",
        "show_plot(fig, PtV, \"photo_vangogh\", i, 6)\n",
        "\n",
        "show_plot(fig, MtV, \"monet_vangogh\", i, 7)\n",
        "show_plot(fig, VtM, \"vangogh_monet\", i, 9)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
